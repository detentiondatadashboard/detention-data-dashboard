{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import yaml\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values for csv importing\n",
    "csv_opts = {'sep': '|',\n",
    "           'quotechar': '\"',\n",
    "           #'compression': 'gzip',\n",
    "           'encoding': 'utf-8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arrest_dtypes.yaml', 'r') as yamlfile:\n",
    "        arrest_dtypes = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in CSV file\n",
    "arrests = pd.read_csv('../../data/arrests.csv', **csv_opts, dtype=arrest_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version https://git-lfs.github.com/spec/v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oid sha256:cfec1b4f2318b0d37781f6b890323d989b4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>size 62293587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          version https://git-lfs.github.com/spec/v1\n",
       "0  oid sha256:cfec1b4f2318b0d37781f6b890323d989b4...\n",
       "1                                      size 62293587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'apprehension_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'apprehension_date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-00886e24bad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#putting event date into m/d/y format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m arrests['apprehension_date'] = pd.to_datetime(\n\u001b[0;32m----> 3\u001b[0;31m     arrests['apprehension_date'], format='%m/%d/%Y')\n\u001b[0m",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maddie/anaconda3/envs/plotting/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'apprehension_date'"
     ]
    }
   ],
   "source": [
    "#putting event date into m/d/y format\n",
    "arrests['apprehension_date'] = pd.to_datetime(\n",
    "    arrests['apprehension_date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FOIA data provided by ICE appears to include complete arrests data for fiscal years 2016-2019 with the exception of the last month of FY 2018. According to ICE's FY2019 reporting, ERO conducted 143,470 arrests in FY2017 and 158,581 arrests in FY2018, which matches the data provided to us (https://www.ice.gov/sites/default/files/documents/Document/2019/eroReportFY2019.pdf). This same report says that in FY2019 ICE made 143,099 arrest, but our data only reports 131,904, which suggests that the difference is from arrests made in September of 2019. Based on ICE's local statistics, these arrests include both criminal and non-criminal arrests (https://www.ice.gov/sites/default/files/documents/Document/2017/localStats2017b.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of variables in arrests dataset\n",
    "arrests.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column heads of arrests dataset\n",
    "arrests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding year and month columns\n",
    "arrests[\"year\"] = arrests[\"apprehension_date\"].dt.strftime('%Y')\n",
    "arrests[\"month\"] = arrests[\"apprehension_date\"].dt.strftime('%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting arrests by fiscal year\n",
    "arrests.set_index('apprehension_date').groupby(\n",
    "    pd.Grouper(freq='AS-OCT'), dropna=False)['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counting arrests by month\n",
    "arrests.set_index('apprehension_date').groupby(\n",
    "    pd.Grouper(freq='MS'), dropna=False)['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customs and Border Protection (CBP) is a significant source of detentions in ICE ERO facilities that does not appear to be included in our datasets on arrests. For example, in FY 2021 ICE reported 21,566 that among 135 of its facilities, 79% of which were detained by CBP (https://www.ice.gov/detain/detention-management). In another report, ICE ERO reported a total detention population in FY2019 of 50,922, 63% of which was due to CBP (https://www.ice.gov/sites/default/files/documents/Document/2019/eroReportFY2019.pdf). This reported decline in detention may be due to the type of facility being measured (inclusion or exclusion of contract facilities and jails/prison) as well as reported declines in detention due to COVID-19 social distancing (https://www.ice.gov/features/ERO-2020). This decline in detention due to COVID-19 is the result of declining intakes from CBP and a possible increase in the number of people on ICE ERO’s non-detained national docket.\n",
    "\n",
    "Additionally, detentions are not only  due to arrests. Rather, initial detentions (excluding transfers between facilities) may be better measured through \"book-ins.\" Book-ins appear to be driven in large part due to CBP apprehensions. According to CBP data,  \"Apprehensions refers to the physical control or temporary detainment of a person who is not lawfully in the U.S. which may or may not result in an arrest.\" Apprehensions are conducted by both Customs and Border Patrol and the Office of Field Operations, and monthly apprehension data is publicly available for both these agencies but only at the geographic level of \"northern\" or \"southern\" border (https://www.cbp.gov/newsroom/stats/cbp-enforcement-statistics/title-8-and-title-42-statistics). More detailed data for \"Encounters\" is available at the state level by FY, but Encounters also includes data on Title 8 Inadmissables, who may or may not make their way into ERO detention centers (https://www.cbp.gov/newsroom/stats/nationwide-encounters). CBP also maintains its own temporary detention centers (including stations and central processing centers), but with a capacity limited to 5,000 and some monthly data on transfers to ICE facilities (https://www.cbp.gov/newsroom/stats/custody-and-transfer-statistics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, BPS only provides limited time series data going back a decade or more. However, five public datasets are possible as useful controls:\n",
    ">\"Total Illegal Alien Apprehensions By Month and Sector FY2000-2020\": https://www.cbp.gov/sites/default/files/assets/documents/2021-Aug/U.S.%20Border%20Patrol%20Monthly%20Encounters%20%28FY%202000%20-%20FY%202020%29%20%28508%29.pdf\n",
    "\n",
    ">\"Annual apprehensions by sector and citizenship FY2007-2020\": https://www.cbp.gov/sites/default/files/assets/documents/2021-Aug/USBORD~3.PDF\n",
    "\n",
    ">\"Total Unaccompanied Alien Children (0-17 Years Old) Apprehensions By Sector and Month FY2010-2019\": https://www.cbp.gov/sites/default/files/assets/documents/2020-Jan/U.S.%20Border%20Patrol%20Total%20Monthly%20UAC%20Apprehensions%20by%20Sector%20%28FY%202010%20-%20FY%202019%29_0.pdf\n",
    "\n",
    ">\"Total Family Unit* Apprehensions By Sector and Month FY2013-2019\": https://www.cbp.gov/sites/default/files/assets/documents/2020-Jan/U.S.%20Border%20Patrol%20Total%20Monthly%20Family%20Unit%20Apprehensions%20by%20Sector%20%28FY%202013%20-%20FY%202019%29_1.pdf\n",
    "\n",
    ">\"BPS Staffing by sector FY1992-2020\": https://www.cbp.gov/sites/default/files/assets/documents/2021-Aug/U.S.%20Border%20Patrol%20Fiscal%20Year%20Staffing%20Statistics%20%28FY%201992%20-%20FY%202020%29%20%28508%29.pdf\n",
    "\n",
    "Additionally, the Office of Immigration Statistics puts out annual data tables between FY2004-2019 that includes apprehensions and removals by agency and sector: https://www.dhs.gov/immigration-statistics/enforcement-actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 1% of all FOIA data provided includes null values, with the exception of 'Apprehension Landmark' and 'Operation.' The former has just under 3% null values, and the latter is redacted so does not include useful data for analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table for null values of arrests\n",
    "# formatting added for commas and percent sign\n",
    "null_table = [['Variable', 'NaN', '% Nan'], \n",
    "              ['AOR', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.aor))), \n",
    "               str(round(sum(pd.isnull(arrests.aor)) / len(arrests) * 100, 2)) +'%'], \n",
    "              ['Apprehension Date', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.apprehension_date))), \n",
    "               str(round(sum(pd.isnull(arrests.apprehension_date)) / len(arrests) * 100, 2)) +'%'], \n",
    "              ['Apprehension Method', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.apprehension_method))), \n",
    "               str(round(sum(pd.isnull(arrests.apprehension_method)) / len(arrests) * 100, 2)) +'%'], \n",
    "              ['Operation', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.operation))), \n",
    "               str(round(sum(pd.isnull(arrests.operation)) / len(arrests) * 100, 2)) +'%'],\n",
    "              ['Apprehension Landmark', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.apprehension_landmark))), \n",
    "               str(round(sum(pd.isnull(arrests.apprehension_landmark)) / len(arrests) * 100, 2)) +'%'], \n",
    "              ['Processing Disposition', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.processing_disposition))), \n",
    "               str(round(sum(pd.isnull(arrests.processing_disposition)) / len(arrests) * 100, 2)) +'%'], \n",
    "              ['Citizenship', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.citizenship))), \n",
    "               str(round(sum(pd.isnull(arrests.citizenship)) / len(arrests) * 100, 2)) +'%'],\n",
    "              ['Gender', \n",
    "               \"{:,}\".format(sum(pd.isnull(arrests.gender))), \n",
    "               str(round(sum(pd.isnull(arrests.gender)) / len(arrests) * 100, 2)) +'%']\n",
    "             ]\n",
    "\n",
    "#print header and table of null values\n",
    "print('')\n",
    "print('Null values for Arrests data (total = 544,059)')\n",
    "print(tabulate(null_table, headers='firstrow', \n",
    "               tablefmt='fancy_grid', stralign='center', numalign='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprehension Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrests across the 24 AORs fluctuate over time (excluding NaN and HQ). Generally, they increase before 2017 and then slightly decrease afterwards. According to ICE reporting, this decrease is due to reallocating staffing resources to border enforcement, indicating that this data does not include arrests by Customs and Border Protection (https://www.ice.gov/sites/default/files/documents/Document/2019/eroReportFY2019.pdf).\n",
    "\n",
    "The largest AORs by arrest volume are those along the southern border, with Chicago being the biggest exception. Looking at apprehension methods over time across all AORs supports this conclusion, with the largest arrests due to interior enforcement and methods such as 'Patrol Border' accounting for just 17 arrests in FY2018.\n",
    "\n",
    "To explore individual AORs over time by arrest method, please see the interactive chart at the bottom of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating subset of arrests by AOR over time\n",
    "arrests_by_fy = arrests[[\"aor\", \"apprehension_date\", \"id\"]]\n",
    "arrests_by_fy = arrests_by_fy.groupby(\n",
    "    [\"aor\", \"apprehension_date\"], as_index=False, dropna=False)['id'].count()\n",
    "\n",
    "# pivot table so dates are rows and AORs are columns\n",
    "arrests_by_fy = arrests_by_fy.pivot(\n",
    "    index='apprehension_date', columns='aor', values='id')\n",
    "\n",
    "# grouping by fiscal year\n",
    "arrests_by_fy = arrests_by_fy.groupby(\n",
    "    pd.Grouper(freq='AS-OCT'), dropna=False).sum()\n",
    "\n",
    "# create plot of arrests over time in each AOR\n",
    "arrests_by_fy.plot().legend(loc='center left',bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "# create transposed table of arrests over time in each AOR\n",
    "arrests_by_fy.T.sort_values(\n",
    "    by=[\"2018-10-01 00:00:00\"], ascending=False).style.format(\"{:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of the number of each arrest method over time\n",
    "arrests_by_method = arrests[[\"apprehension_date\", \"apprehension_method\", \"id\"]]\n",
    "arrests_by_method = arrests_by_method.groupby([\"apprehension_method\", \"apprehension_date\"],\n",
    "                                              as_index=False, dropna=False)['id'].count()\n",
    "\n",
    "# pivot table so dates are in rows and arrest method is in columns\n",
    "arrests_by_method = arrests_by_method.pivot(\n",
    "    index='apprehension_date', columns='apprehension_method', values='id')\n",
    "\n",
    "# group by fiscal year\n",
    "arrests_by_method = arrests_by_method.groupby(pd.Grouper(freq='AS-OCT')).sum()\n",
    "\n",
    "# create plot of arrest methods over time\n",
    "arrests_by_method.plot().legend(loc='center left',bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "# create table of arrests methods over fiscal year\n",
    "arrests_by_method.transpose().sort_values(\n",
    "    by=[\"2018-10-01 00:00:00\"], ascending=False).style.format(\"{:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprehension Methods within AOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of arrest method over time in each AOR\n",
    "arrests_by_method = arrests[[\"aor\", \"apprehension_date\", \"apprehension_method\", \"id\"]]\n",
    "arrests_by_method = arrests_by_method.groupby(\n",
    "    [\"aor\", \"apprehension_date\", \"apprehension_method\"], \n",
    "    as_index=False, dropna=False)['id'].count()\n",
    "\n",
    "#create set of unique AORs, excluding NAN\n",
    "foo = set(arrests['aor'])\n",
    "foo.remove(np.nan)\n",
    "\n",
    "# function that returns the arrests methods by fiscal year for a given AOR\n",
    "def aor_arrest_methods(place):\n",
    "    # subset arrest methods by given AOR\n",
    "    arrests_by_method_aor = arrests_by_method.loc[\n",
    "        arrests_by_method[\"aor\"] == place]\n",
    "\n",
    "    # pivot table so date is in rows and method in columns\n",
    "    arrests_by_method_aor = arrests_by_method_aor.pivot(\n",
    "        index='apprehension_date', columns='apprehension_method', values='id')\n",
    "\n",
    "    # group by fiscal year\n",
    "    arrests_by_method_aor = arrests_by_method_aor.groupby(\n",
    "        pd.Grouper(freq='AS-OCT'), dropna=False).sum()\n",
    "\n",
    "    #transpose table\n",
    "    arrests_by_method_aor = arrests_by_method_aor.transpose()\n",
    "\n",
    "    #sort values descending by most recent fiscal year\n",
    "    arrests_by_method_aor = arrests_by_method_aor.sort_values(\n",
    "        by=[arrests_by_method_aor.columns[3]], ascending=False).style.format(\"{:,.0f}\")\n",
    "\n",
    "    #return table of sorted arrest methods for given AOR\n",
    "    return display(arrests_by_method_aor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create widget for drop down menu of AORs\n",
    "widgets.interact(aor_arrest_methods, place = foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprehension Method across AORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of unique apprehension methods\n",
    "fob = set(arrests['apprehension_method'])\n",
    "\n",
    "# function to return number of arrest methods across AORs\n",
    "def aors_by_method(method):\n",
    "    # create subset of arrests for a given method\n",
    "    arrests_CAP = arrests[arrests['apprehension_method'].isin([method])]\n",
    "\n",
    "    # return the number of a given arrest methods across AORs\n",
    "    return arrests_CAP['aor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create widget with drop down menu to select arrest methods\n",
    "widgets.interact(aors_by_method, method = fob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landmarks are the only geographic identifier in the dataset that is more precise than the AOR level. \n",
    "There are 7,279 unique landmarks in the dataset, though first grouping the data by AOR results in 8,012 unique landmarks, suggesting that landmarks names are duplicated in different AORs. Most of the arrests occur in a small subset of these landmarks inidcated by the below histograph.\n",
    "\n",
    "Geocoding these references poses a number of challenges. A significant number of landmarks include the term 'non-specific' in their title, making it difficult to identify where these landmarks are. For example, 'non-specific' appears in almost 60% of the arrests made in the aor 'LOS'. However, 'non-specific' appears in less than 1% of all arrests in the aor 'PHO.' Many, though not all, of these non-specific landmarks appear to be named after ERO field offices (https://www.ice.gov/doclib/about/offices/ero/pdf/eroFieldOffices.pdf). However, the operational area for these field offices frequently cross county and state lines (https://uwchr.github.io/i-213-analysis/), posing further complications for geocoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series of how many unique landmarks there are, regardless of capitalization\n",
    "arrests_landmarks = arrests.apprehension_landmark.str.upper().value_counts()\n",
    "arrests_landmarks.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of location variables, counting IDs\n",
    "arrests_distinct_landmarks = arrests[\n",
    "    ['aor', 'apprehension_landmark', 'id']].groupby(\n",
    "    ['aor', 'apprehension_landmark'], as_index=False, dropna=False).count()\n",
    "\n",
    "# display all locations with at least one arrest, sorted by largest to smallest\n",
    "arrests_distinct_landmarks.loc[\n",
    "    arrests_distinct_landmarks['id'] > 0].sort_values('id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a historgram of arrests landmarks in groups of 100\n",
    "arrests_landmarks.plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a column to arrests dataset that contains a binary indicator \n",
    "# of whether the landmark includes the term 'non-specific'\n",
    "arrests['non-specific'] = arrests[\n",
    "    'apprehension_landmark'].str.contains(\n",
    "    'non-specific', case=False, na=False).astype(int)\n",
    "\n",
    "# create subset and calculate for each AOR \n",
    "# the number of non-specific occurences divided by the total number of arrests\n",
    "# sort resulting proportions from largest to smallest\n",
    "dub = arrests[['aor','id', 'non-specific']]\n",
    "dub = dub.groupby('aor')['non-specific'].sum()/dub.groupby('aor')['id'].count()\n",
    "dub.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Ten Landmarks by AOR (aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of arrests by location\n",
    "arrests_location = arrests.groupby(\n",
    "    ['aor', 'apprehension_landmark'], as_index=False, dropna=False)['id'].count()\n",
    "\n",
    "# create a subset of the ten largest landmarks in each AOR\n",
    "arrests_aor_agg = arrests_location.sort_values(['aor', 'id'], ascending=False).groupby(\n",
    "    'aor', dropna=False).head(10)\n",
    "\n",
    "# create a list of AORs in the dataset, excluding NAN\n",
    "fub = set(arrests['aor'])\n",
    "fub.remove(np.nan)\n",
    "\n",
    "# function that creates a plot of the top ten largest landmarks when given an AOR\n",
    "def top_landmarks_aggregate(place):\n",
    "    arrests_aor_agg.loc[arrests_aor_agg['aor'] == place].plot(\n",
    "        y='id', x='apprehension_landmark', kind='barh').invert_yaxis()\n",
    "    plt.title(place + \" \" + str(arrests.loc[arrests['aor'] == place]['id'].count()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a plot that can select an AOR using a drop down widget\n",
    "widgets.interact(top_landmarks_aggregate, place = fub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Ten Landmarks by AOR (proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in subset of arrests by location \n",
    "# that is the sum of all arrests in that AOR\n",
    "arrests_location['aor total'] = arrests_location.groupby(\n",
    "    'aor', sort=False, dropna=False)[\"id\"].transform('sum')\n",
    "\n",
    "# create new column in subset of arrests by location that is the \n",
    "# proportion of arrests in a landmark divided by the total arrests in that AOR\n",
    "arrests_location['aor proportion'] = arrests_location['id']/arrests_location['aor total']\n",
    "\n",
    "# create a subset of the top ten most common landmarks in each AOR\n",
    "arrests_aor_prop = arrests_location.sort_values(['aor', 'id'], ascending=False).groupby(\n",
    "    'aor', dropna=False).head(10)\n",
    "\n",
    "# function creates a plot of the proportion of the top ten largest landmarks in a given AOR\n",
    "def top_landmarks_proportion(place):\n",
    "    arrests_aor_prop.loc[arrests_aor_prop['aor'] == place].plot(\n",
    "        y='aor proportion', x='apprehension_landmark', kind='barh').invert_yaxis()\n",
    "    plt.title(place + \" \" + str(arrests.loc[arrests['aor'] == place]['id'].count()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interact(top_landmarks_proportion, place = fub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of encounters with date, processing disposition and ID\n",
    "arrests_by_disposition = arrests[\n",
    "    [\"apprehension_date\", \"processing_disposition\", \"id\"]]\n",
    "\n",
    "# count the number of arrests by each type of processing disposition and date\n",
    "arrests_by_disposition = arrests_by_disposition.groupby(\n",
    "    [\"processing_disposition\", \"apprehension_date\"], \n",
    "    as_index=False, dropna=False)['id'].count()\n",
    "\n",
    "# pivot df so that index is date and columns are processing disposition \n",
    "# (allows for easy groupby in next line of code)\n",
    "arrests_by_disposition = arrests_by_disposition.pivot(\n",
    "    index='apprehension_date', columns='processing_disposition', values='id')\n",
    "\n",
    "# group by fiscal year\n",
    "arrests_by_disposition = arrests_by_disposition.groupby(\n",
    "    pd.Grouper(freq='AS-OCT'), dropna=False).sum()\n",
    "\n",
    "# plot disposition types over time\n",
    "arrests_by_disposition.plot().legend(loc='center left',bbox_to_anchor=(1.1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose table of transposed df to show disposition types over fiscal years\n",
    "arrests_by_disposition.transpose().sort_values(by=[\"2018-10-01 00:00:00\"], ascending=False).style.format(\"{:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citizenship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of arrests frequency by citizenship\n",
    "arr_cit = arrests.citizenship.value_counts(normalize=True).to_frame()\n",
    "\n",
    "# renames column header\n",
    "arr_cit.columns = [\"arrests\"]\n",
    "\n",
    "# converts column to percent\n",
    "arr_cit = arr_cit*100\n",
    "arr_cit = arr_cit.round(decimals=2)\n",
    "arr_cit = arr_cit.sort_values(by = ['arrests'], ascending=False)\n",
    "arr_cit = arr_cit.astype(str) + '%'\n",
    "\n",
    "# displays results\n",
    "arr_cit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "481px",
    "left": "26px",
    "top": "111.133px",
    "width": "326.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
